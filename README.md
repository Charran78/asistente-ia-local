# Asistente IA Local

Interfaz web para interactuar con modelos de lenguaje a través de Ollama, construida con Gradio.

## Características

- Interfaz web amigable con Gradio
- Historial de conversaciones persistente en SQLite
- Soporte para diferentes modelos de Ollama
- Ajuste de parámetros como temperatura
- Visualización del historial de conversaciones

## Instalación

1. Clona el repositorio:
```bash
git clone https://github.com/charran78/asistente-ia-local.git
cd asistente-ia-local